#!/bin/bash

# SPDX-FileCopyrightText: 2009 Fermi Research Alliance, LLC
# SPDX-License-Identifier: Apache-2.0

###########################
# Logging utilities
#
# Every logged event is recorded in a separate file. Eventually, these shards
# are merged into a single log file; metadata is added at the beginning.
# Logs are sent to one or more remote servers via https.

log_initialized=0
log_ready=0
log_no_send=1

warn_ready() {
    # Print a warning message in the stderr about logging not being setup

    [ -z "${GLIDEIN_QUIET}" ] &&  warn "$@"
}

warn() {
    # Print a warning message in the stderr
    # Note: this func is also defined in glidein_startup, which needs it early

    echo "WARN $(date)" "$@" 1>&2
}


serialize_assoc_arr() {
    # Serialize an associative array to a file
    # To deserialize, use:
    #   eval "declare -A <arr>=$(cat <file>)"
    #
    # Arguments:
    #   1: outfile, 2: associative array name

    local outfile="$1"
    local disp_arr="$(declare -p "$2")"
    echo "${disp_arr#*=}" > "${outfile}"
}


generate_glidein_metadata_json() {
    # Create a log shard file containing information about the glidein

    if command -v jq >/dev/null 2>&1; then
        json_metadata=$( jq -n \
                  --arg uuid "${glidein_uuid}" \
                  --arg name "${glidein_name}" \
                  --arg fact "${glidein_factory}" \
                  --arg entry "${glidein_entry}" \
                  --arg client "${client_name}" \
                  --arg client_group "${client_group}" \
                  --arg cred "${glidein_cred_id}" \
                  --arg cluster "${condorg_cluster}" \
                  --arg subcluster "${condorg_subcluster}" \
                  --arg schedd "${condorg_schedd}" \
                  --arg debug "${set_debug}" \
                  --arg startup_pid "$$" \
                  --arg tmpdir "${glide_tmp_dir}" \
                  --arg local_tmpdir "${glide_local_tmp_dir}" \
                  --arg proxy "${proxy_url}" \
                  --arg desc_file "${descript_file}" \
                  --arg desc_entry_file "${descript_entry_file}" \
                  --arg signature "${sign_id}" \
                  --arg entry_signature "${sign_entry_id}" \
                  '{UUID: $uuid, name: $name, factory: $fact, entry: $entry, client: $client, client_group: $client_group, cred_id: $cred, cluster: $cluster, subcluster: $subcluster, schedd: $schedd, debug: $debug, startup_pid: $startup_pid, tmpdir: $tmpdir, local_tmpdir: $local_tmpdir, proxy: $proxy, desc_file: $desc_file, desc_entry_file: $desc_entry_file, signature: $signature, entry_signature: $entry_signature}' )
    else
        # Fallback for jq
        json_metadata="{\"uuid\":\"${glidein_uuid}\", \"name\":\"${glidein_name}\", \"factory\":\"${glidein_factory}\", \"entry\":\"${glidein_entry}\", \"client\":\"${client_name}\", \"client_group\":\"${client_group}\", \"cred_id\":\"${glidein_cred_id}\", \"cluster\":\"${condorg_cluster}\", \"subcluster\":\"${condorg_subcluster}\", \"schedd\":\"${condorg_schedd}\",\"debug\":\"${set_debug}\", \"startup_pid\":\"$$\", \"tmpdir\":\"${glide_tmp_dir}\", \"local_tmpdir\":\"${glide_local_tmp_dir}\", \"proxy\":\"${proxy_url}\", \"desc_file\":\"${descript_file}\", \"desc_entry_file\":\"${descript_entry_file}\", \"signature\":\"${sign_id}\", \"entry_signature\":\"${sign_entry_id}\"}"  # TODO: escaping may be needed
    fi
    echo "${json_metadata}" > "${logdir}/glidein_metadata.json"
}


log_init_tokens() {
    # Process the tokens received from the factory to authenticate with log server:
    # keep only the necessary ones, delete everything else
    # An associative array is created and serialized: it maps server urls to tokens
    # Arguments:
    #   1: array or recipients (urls)

    local recipients=("$@")
    if [ "${#recipients[@]}" -eq 0 ]; then
        warn "log_init_tokens: empty argument (list of recipients)"
        return 1
    fi

    if [ ! -f tokens.tgz ] || [ ! -f url_dirs.desc ]; then
        warn "log_init_tokens: missing token files (tar and descriptor)"
        return 2
    fi

    if ! tar xf tokens.tgz; then
        warn "log_init_tokens: failed to untar the tokens archive"
        return 3
    fi

    declare -A tokens_arr
    for recip in "${recipients[@]}"; do
        local recip_dir="$(grep "^${recip} " url_dirs.desc | cut -d ' ' -f 2-)"
        local vofe_token_name="TODO"    # TODO: get the name of the frontend + group
        if [ -f "tokens/${recip_dir}/${vofe_token_name}" ]; then
            # Use the token signed by the frontend
            tokens_arr["${recip}"]=$(cat tokens/${recip_dir}/${vofe_token_name}.jwt)
        elif [ -f "tokens/${recip_dir}/default.jwt" ]; then
            # Use the token signed by the factory
            tokens_arr["${recip}"]=$(cat tokens/${recip_dir}/default.jwt)
        else
            warn "log_init_tokens: could not find any valid token for ${recip}"
            # TODO: maybe fail only for this recipient, still serving the others?
            return 4
        fi
    done

    serialize_assoc_arr "tokens_arr" tokens_arr

    # It's important to remove these files because they contain private information
    rm -rf tokens.tgz url_dirs.desc tokens
}


log_init() {
    # Initializes the log utility with the specified configuration.
    # This also creates the necessary folders, and should be called only once per glidein.
    # Arguments:
    #   1: glidein_uuid, 2: relative_basepath

    # Validate number of arguments
    if [ "$#" -ne 2 ]; then
        warn "log_init: could not initialize log. Expected 2 arguments, got $#."
        return 1
    fi

    # Inherit glidein_config from caller. It is necessary for logging to be properly configured.
    if [ ! -f "${glidein_config}" ]; then
        warn "log_init: glidein_config not defined in ${0}. Logging will not work here."
        return 2
    else
        add_config_line_source=$(grep -m1 '^ADD_CONFIG_LINE_SOURCE ' "${glidein_config}" | cut -d ' ' -f 2-)
        # shellcheck source=./add_config_line.source
        . "${add_config_line_source}"
    fi

    logdir="logs/${1}"
    stdout_logfile="${1}.out"
    stderr_logfile="${1}.err"
    log_logfile="${1}.log"
    log_relative_basepath="${2}"

    # Export configuration
    gconfig_add "GLIDEIN_LOGDIR" "${logdir}"
    gconfig_add "GLIDEIN_STDOUT_LOGFILE" "${stdout_logfile}"
    gconfig_add "GLIDEIN_STDERR_LOGFILE" "${stderr_logfile}"
    gconfig_add "GLIDEIN_LOG_LOGFILE" "${log_logfile}"
    gconfig_add "GLIDEIN_LOG_RELATIVE_BASEPATH" "${log_relative_basepath}"
    if [ -n "${LOG_RECIPIENTS}" ]; then
        gconfig_add "GLIDEIN_LOG_RECIPIENTS" "${LOG_RECIPIENTS}"
    fi

    # Setup tokens to authenticate with log servers
    log_recipients=($(gconfig_get GLIDEIN_LOG_RECIPIENTS "${glidein_config}"))
    local no_send=0
    if [ "${#log_recipients[@]}" -eq 0 ]; then
        warn "log_init: no recipients configured. Logs will still be produced, but not forwarded to remote servers."
        no_send=1
    elif ! log_init_tokens "${log_recipients[@]}"; then
        warn "log_init: error while initializing tokens. Logs will still be produced, but not forwarded to remote servers."
        no_send=1
    fi

    # Check if curl is installed
    if command -v curl >/dev/null 2>&1; then
        curl_version=$(curl --version 2>&1 | head -1)
    else
        curl_version="not installed"
        warn "log_init: curl not installed. Logs will still be produced, but not forwarded to remote servers."
        no_send=1
    fi

    gconfig_add "CURL_VERSION" "${curl_version}"
    gconfig_add "GLIDEIN_LOG_NO_SEND" "${no_send}"

    # Create the necessary folders
    mkdir -p "${logdir}/shards/creating"

    # Create an 'empty' log, containing only glidein metadata
    generate_glidein_metadata_json
    echo "[" > "${logdir}/${log_logfile}"
    cat "${logdir}/glidein_metadata.json" >> "${logdir}/${log_logfile}"
    echo "]" >> "${logdir}/${log_logfile}"

    # Log a copy of stdout and stderr too
    exec >  >(tee -ia "${logdir}/${stdout_logfile}")
    exec 2> >(tee -ia "${logdir}/${stderr_logfile}" >&2)
    echo "$(date): Started logging stdout on file too"
    echo "$(date): Started logging stderr on file too" >&2

    gconfig_add "GLIDEIN_LOG_INITIALIZED" "1"
}


log_setup() {
    # Setup the logging utilities for the caller script with the specified configuration
    # Arguments:
    #   1: glidein config filename

    # Validate number of arguments
    if [ "$#" -ne 1 ]; then
        warn "log_setup: could not setup log for ${0}. Expected 1 arguments, got $#."
        return 1
    fi
    local glidein_config=${1}

    if [ ! -f "${glidein_config}" ]; then
        warn "log_setup: glidein_config not defined in ${0}. Logging will not work here."
        return 1
    fi

    log_initialized=$(gconfig_get GLIDEIN_LOG_INITIALIZED "${glidein_config}")
    if [ "${log_initialized}" != 1 ]; then
        warn_ready "log_setup: apparently the logging configuration has not been initialiazed yet (${0}). Logging will not work here."
        return 1
    fi

    logdir=$(gconfig_get GLIDEIN_LOGDIR "${glidein_config}")
    stdout_logfile=$(gconfig_get GLIDEIN_STDOUT_LOGFILE "${glidein_config}")
    stderr_logfile=$(gconfig_get GLIDEIN_STDERR_LOGFILE "${glidein_config}")
    log_logfile=$(gconfig_get GLIDEIN_LOG_LOGFILE "${glidein_config}")
    log_recipients=($(gconfig_get GLIDEIN_LOG_RECIPIENTS "${glidein_config}"))
    log_no_send=$(gconfig_get GLIDEIN_LOG_NO_SEND "${glidein_config}")
    log_relative_basepath=$(gconfig_get GLIDEIN_LOG_RELATIVE_BASEPATH "${glidein_config}")
    curl_version=$(gconfig_get CURL_VERSION "${glidein_config}")

    if [ "${log_no_send}" -ne 0 ]; then
        log_no_send=1
    fi

    log_ready=1
}


json_escape() {
    # Escape json special characters
    # Arguments:
    #   1: text to escape

    qstr="$(printf '%s' "$1" | python -c 'import json,sys; print(json.dumps(sys.stdin.read()))')"
    # Remove unwanted outer double quotes
    qstr="${qstr%\"}"
    qstr="${qstr#\"}"
    echo "${qstr}"
}


get_logfile_path_relative() {
    # Get the relative path of the logfile w.r.t. the work dir

    if [ "${log_ready}" != 1 ]; then
        warn_ready "get_logfile_path_relative: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 1
    fi
    echo "${logdir}/${log_logfile}"
}


log_write() {
    # Log an event. This involves the creation of a 'shard', i.e. a file storing the log entry
    # The content can include either a string or the body of a file (encoded in base64)
    # If type is file, then the filepath can be either absolute or relative to work_dir
    #
    # Arguments
    #   1:invoker, 2:type of message, 3:content/filepath, 4:severity

    if [ "${log_ready}" != 1 ]; then
        warn_ready "log_write: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 1
    fi

    cur_time=$(date +%Y-%m-%dT%H:%M:%S%:z)
    cur_time_ns=$(date +%s%N)   # enough to ensure that shards have different timestamps

    # Source encoding utilities
    b64uuencode_source=$(gconfig_get B64UUENCODE_SOURCE "${glidein_config}")
    source "${b64uuencode_source}"

    # Argument $1 (invoker)
    invoker="$1"
    # Argument $2 (type)
    case $2 in
        "text" | "file" ) type=$2;;
        *) type="text";;
    esac
    # Argument $3 (content/filepath)
    if [ "$type" = "file" ]; then
        filename="$3"
        case ${filename} in
            /*) filepath="${filename}";;                            # absolute
             *) filepath="${log_relative_basepath}/${filename}";;   # relative
        esac
        raw_content=$(cat "${filepath}")
        if [ -z "${raw_content}" ]; then
            raw_content="File not found"
        fi
        # Compression and encoding
        content=$(echo "${raw_content}" | gzip --stdout - | b64uuencode | tr -d '\n\r')
    else
        filename=""
        content="$3"
    fi
    # Argument $4 (severity)
    case $4 in
        "error" | "warn" | "info" | "debug" | "fatal" ) severity=$4;;
        *) severity="info";;
    esac

    pid=${BASHPID:-$$}
    shard_filename="${cur_time_ns}_${invoker}_${pid}_${type}_${severity}.shard"

    # Create a JSON shard containing all the required attributes.
    # This operation must be atomic, to avoid race conditions with log_coalesce shards.
    # The idea is to exploit the atomicity of the command 'mv' (at least in local fs),
    # whereas 'echo' (which leverages OS write) is not.
    # So, it first writes to a safe location, then moves the shard (atomically) where needed.
    pushd "${log_relative_basepath}/${logdir}/shards" > /dev/null
    touch "creating/${shard_filename}"
    if command -v jq >/dev/null 2>&1; then
        json_logevent=$( jq -n \
                  --arg inv "${invoker}" \
                  --arg pid "${pid}" \
                  --arg ts "${cur_time}" \
                  --arg ty "${type}" \
                  --arg fn "${filename}" \
                  --arg body "${content}" \
                  --arg sev "${severity}" \
                  '{invoker: $inv, pid: $pid, timestamp: $ts, severity: $sev, type: $ty, filename: $fn, content: $body}' )
    else
        invoker="$(json_escape "${invoker}")"
        content="$(json_escape "${content}")"
        json_logevent="{\"invoker\":\"${invoker}\", \"pid\":\"${pid}\", \"timestamp\":\"${cur_time}\", \"severity\":\"${severity}\", \"type\":\"${type}\", \"filename\":\"${filename}\", \"content\":\"${content}\"}"
    fi

    echo "${json_logevent}" > "creating/${shard_filename}"
    mv "creating/${shard_filename}" "${shard_filename}"
    popd > /dev/null
}


log_coalesce_shards() {
    # Merge log shards in a single file (for each glidein process)
    # Skip (and return with code 1) if another process is already coaleascing,
    # so that this operation is non-blocking. Retcode 1 may be exploited to loop
    # log_coalesce_shards until it succeeds, when you want to force the merging

    if [ "${log_ready}" != 1 ]; then
        warn_ready "log_coalesce_shards: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 2
    fi

    pushd "${log_relative_basepath}/${logdir}" > /dev/null

    if mkdir shards/coalescing; then
        # Coalescing is performed in a separate directory, to avoid
        # interference from other processes calling log_write in the meanwhile.
        # Only one process at a time is allowed to use the merging folder.
        # The 'trylock' is based on the atomicity of the mkdir command
        cur_time=$(date +%Y-%m-%dT%H:%M:%S%:z)
        if [ -n "$(find shards -maxdepth 1 -type f)" ]; then
            cp "${log_logfile}" shards/coalescing/
            mv shards/*.shard shards/coalescing/
            pushd shards/coalescing > /dev/null
            sed -i '$ {s/]$/,/}' "${log_logfile}"   # replace last square bracket with comma
            for shd in *.shard; do                  # concatenate separating with comma
                cat "${shd}"
                echo ","
            done >> "${log_logfile}"
            sed -i '$ d' "${log_logfile}"           # remove last comma
            echo "]" >> "${log_logfile}"            # closing square bracket
            popd > /dev/null
            mv "shards/coalescing/${log_logfile}" .
        fi
        rm -rf shards/coalescing
        popd > /dev/null
        return 0
    else
        popd > /dev/null
        return 1
    fi
}

send_logs_to_remote() {
    # Forward the logs to a remote HTTPS server.
    # A token must be included in the header for authentication.
    # Note:
    #   it also merges the shards before sending

    if ! log_coalesce_shards; then
        return 1
    fi

    # log_no_send is set when the recipients initialization failed for some
    # reason, but the system is still capable of producing logs
    if [ "${log_no_send}" = 1 ]; then
        return 1
    fi

    # Retrieve the tokens (by deserializing the tokens_arr file)
    if [ ! -f tokens_arr ]; then
        warn "send_logs_to_remote: cannot find tokens_arr file"
        return 1
    fi
    eval "declare -A tokens_arr=$(cat tokens_arr)"

    # Upload stdout, stderr and log file
    logfiles=("${stdout_logfile}" "${stderr_logfile}" "${log_logfile}")

    for recipient_addr in "${log_recipients[@]}"; do
        for logfile in "${logfiles[@]}"; do
            curl_resp=$(curl -X PUT --upload-file "${log_relative_basepath}/${logdir}/${logfile}" "${recipient_addr}/${logfile}" -H "Authorization: Bearer ${tokens_arr["${recipient_addr}"]}" 2>&1)
            curl_retval=$?
            if [ ${curl_retval} -ne 0 ]; then
                warn "Failed to deliver ${logfile} to remote server (${recipient_addr}). curl_version: ${curl_version} curl_exit_code: ${curl_retval} curl_err_msg: ${curl_resp}"
            fi
        done
    done
}
